the next obvious step is to build a kind of automated profit analysis script

we can take the names for each link, chop them up, and use them to form what I'll call
a composite string. Say we take some raw name:

apple macbook pro a1706 13.3 inch laptop - mpxv2ll/a (2017)

There are a number of tokens we are interested in in order to build the composite string that
we will use for the search query. Specifically, the strings:

1. Apple
2. Macbook
3. Pro
4. Model Number
5. Year

We order those tokens from the raw name and then build the composite string for the search query
Then we use that to build the link, pipe that into a bs4 python script, and strip the wget-ed file
for useful data. 

We have hundreds of items here, so we don't want to repeatedly download and strip html for data
that we already have, so we need a small database that we will just have to update periodically
to maintain the accuracy of the data.

We're going to have to form the composite string for every item in the list, so we need an efficient
way to strip its items and determine whether or not we already have the data stored before we
initiate a query to eBay. 

We can use some kind of hashtable implementation to flip through our existing database of recent
pricing for items, and it's going to make more sense to program that in C++.

So then I suppose the first logical step would be to create a mechanism by which the item names are
broken down into their composite tokens (done, with the stringProcessor.py script), and then
